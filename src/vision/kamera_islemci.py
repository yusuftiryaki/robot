"""
üì∑ Kamera ƒ∞≈ülemci - Robot'un G√∂zleri
Hacƒ± Abi'nin g√∂r√ºnt√º i≈üleme algoritmasƒ± burada!

Bu sƒ±nƒ±f robot'un kamerasƒ±ndan g√∂r√ºnt√º i≈üler:
- Engel tanƒ±ma ve sƒ±nƒ±flandƒ±rma
- ≈ûarj istasyonu tespiti
- Otlak alanƒ± analizi
- G√∂rsel odometri (opsiyonel)
"""

# OpenCV import - dev container OpenGL sorunu i√ßin ko≈üullu
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è  OpenCV import hatasƒ±: {e}")
    print("   Dev container'da OpenGL sorunu olabilir")
    CV2_AVAILABLE = False
    # Dummy cv2 module for dev environment

    class DummyCV2:
        def __init__(self):
            self.CAP_PROP_FRAME_WIDTH = 3
            self.CAP_PROP_FRAME_HEIGHT = 4
            self.CAP_PROP_FPS = 5
            self.COLOR_BGR2RGB = 4
            self.COLOR_BGR2HSV = 40
            self.COLOR_HSV2BGR = 54
            self.INTER_AREA = 3
            self.MORPH_CLOSE = 3
            self.MORPH_OPEN = 2
            self.MORPH_RECT = 0
            self.THRESH_BINARY = 0
            self.THRESH_OTSU = 8

        def VideoCapture(self, *args):
            return DummyVideoCapture()

        def resize(self, img, size, interpolation=None):
            return np.zeros((*size[::-1], 3), dtype=np.uint8)

        def cvtColor(self, img, code):
            return img

        def threshold(self, img, thresh, maxval, type):
            return thresh, img

        def morphologyEx(self, img, op, kernel):
            return img

        def getStructuringElement(self, shape, ksize):
            return np.ones(ksize, dtype=np.uint8)

        def findContours(self, img, mode, method):
            return [], []

        def contourArea(self, contour):
            return 0

        def boundingRect(self, contour):
            return (0, 0, 0, 0)

        def rectangle(self, img, pt1, pt2, color, thickness):
            return img

        def putText(self, img, text, org, fontFace, fontScale, color, thickness):
            return img

        @property
        def FONT_HERSHEY_SIMPLEX(self):
            return 0

        def imencode(self, ext, img):
            return True, b'dummy_image_data'

    class DummyVideoCapture:
        def __init__(self):
            self.opened = False

        def isOpened(self):
            return self.opened

        def read(self):
            return False, np.zeros((480, 640, 3), dtype=np.uint8)

        def release(self):
            pass

        def set(self, prop, value):
            pass

        def get(self, prop):
            return 0

    cv2 = DummyCV2()

import asyncio
import json
import logging
import time
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

import numpy as np


class EngelTipi(Enum):
    """Engel tipi enum'u"""
    BILINMEYEN = "bilinmeyen"
    AGAC = "agac"
    TAS = "tas"
    DUVAR = "duvar"
    INSAN = "insan"
    HAYVAN = "hayvan"
    ARAC = "arac"


@dataclass
class Engel:
    """Tespit edilen engel"""
    tip: EngelTipi
    konum: Tuple[int, int]  # (x, y) pixel koordinatƒ±
    boyut: Tuple[int, int]  # (geni≈ülik, y√ºkseklik)
    mesafe: float  # tahmini mesafe (metre)
    guven_skoru: float  # 0-1 arasƒ±


@dataclass
class SarjIstasyonu:
    """≈ûarj istasyonu tespiti"""
    tespit_edildi: bool
    konum: Tuple[int, int]  # merkez koordinatƒ±
    mesafe: float  # tahmini mesafe
    yon: float  # radyan cinsinden y√∂n
    guven_skoru: float


class KameraIslemci:
    """
    üì∑ Ana Kamera ƒ∞≈ülemci Sƒ±nƒ±fƒ±

    Raspberry Pi kamerasƒ±ndan g√∂r√ºnt√º alƒ±r ve i≈üler.
    OpenCV ile g√∂r√ºnt√º analizi yapar.
    """

    def __init__(self, camera_config: Dict[str, Any]):
        self.config = camera_config
        self.logger = logging.getLogger("KameraIslemci")

        # Kamera parametreleri - Config'ten al
        # Resolution - hem [width, height] hem de {width: x, height: y} formatlarƒ±nƒ± destekle
        resolution_config = camera_config.get("resolution", [640, 480])
        if isinstance(resolution_config, list):
            # [width, height] formatƒ±nda
            self.resolution = tuple(resolution_config)
        else:
            # {width: x, height: y} formatƒ±nda
            self.resolution = tuple((
                resolution_config.get("width", 640),
                resolution_config.get("height", 480)
            ))
        self.framerate = camera_config.get("fps", 30)
        self.device_id = camera_config.get("device_id", 0)
        self.auto_exposure = camera_config.get("auto_exposure", True)

        # Sim√ºlasyon parametreleri
        simulation_params = camera_config.get("simulation_params", {})
        self.test_pattern = simulation_params.get("test_pattern", True)
        self.noise_level = simulation_params.get("noise_level", 0.05)

        # Sim√ºlasyon modu
        self.simulation_mode = self._is_simulation()

        # Kamera objesi
        self.camera = None
        self.son_goruntu = None
        self.goruntu_sayaci = 0

        # Engel tespit parametreleri
        self.engel_min_alan = 500  # pixel¬≤
        self.engel_max_alan = 50000  # pixel¬≤

        # ≈ûarj istasyonu tespit parametreleri (IR LED'ler i√ßin)
        self.sarj_ir_threshold = 200
        self.sarj_min_contour_area = 100

        # Kalibrasyon parametreleri
        self.camera_matrix = None
        self.dist_coeffs = None

        # Engel tanƒ±ma i√ßin basit renk aralƒ±klarƒ±
        self.renk_araliklari = {
            "yesil": {"lower": np.array([40, 40, 40]), "upper": np.array([80, 255, 255])},
            "kahverengi": {"lower": np.array([10, 50, 20]), "upper": np.array([20, 255, 200])},
            "gri": {"lower": np.array([0, 0, 50]), "upper": np.array([180, 30, 200])}
        }

        self.logger.info(
            f"üì∑ Kamera i≈ülemci ba≈ülatƒ±ldƒ± (Sim√ºlasyon: {self.simulation_mode})")
        self.logger.info(f"üì∑ √á√∂z√ºn√ºrl√ºk: {self.resolution}, FPS: {self.framerate}")
        if self.simulation_mode:
            self.logger.info(f"üì∑ Sim√ºlasyon: Test pattern: {self.test_pattern}, Noise: {self.noise_level}")
        self._init_camera()

    def _is_simulation(self) -> bool:
        """Sim√ºlasyon modunda mƒ± kontrol et"""
        try:
            from picamera2 import Picamera2
            return False
        except ImportError:
            return True

    def _init_camera(self):
        """Kamerayƒ± ba≈ülat"""
        if self.simulation_mode:
            self._init_simulation_camera()
        else:
            self._init_real_camera()

    def _init_simulation_camera(self):
        """Sim√ºlasyon kamerasƒ± ba≈ülat - Config'ten ayarlarƒ± kullan"""
        self.logger.info("üîß Sim√ºlasyon kamerasƒ± ba≈ülatƒ±lƒ±yor...")

        # Config'ten sim√ºlasyon ayarlarƒ±nƒ± al
        if self.test_pattern:
            # Test paterni ile g√∂r√ºnt√º olu≈ütur
            self.son_goruntu = self._create_test_pattern()
        else:
            # D√ºz ye≈üil g√∂r√ºnt√º olu≈ütur
            self.son_goruntu = np.zeros(
                (self.resolution[1], self.resolution[0], 3), dtype=np.uint8)
            self.son_goruntu[:, :] = [0, 150, 0]  # Ye≈üil √ßimen rengi

        # Noise ekle
        if self.noise_level > 0:
            self._add_noise_to_image()

        self.logger.info("‚úÖ Sim√ºlasyon kamerasƒ± hazƒ±r!")

    def _create_test_pattern(self) -> np.ndarray:
        """Test paterni olu≈ütur"""
        img = np.zeros((self.resolution[1], self.resolution[0], 3), dtype=np.uint8)

        # Satran√ß tahtasƒ± paterni
        square_size = 50
        for i in range(0, self.resolution[1], square_size):
            for j in range(0, self.resolution[0], square_size):
                if (i // square_size + j // square_size) % 2 == 0:
                    img[i:i + square_size, j:j + square_size] = [255, 255, 255]  # Beyaz
                else:
                    img[i:i + square_size, j:j + square_size] = [0, 0, 0]  # Siyah

        return img

    def _add_noise_to_image(self):
        """G√∂r√ºnt√ºye noise ekle"""
        if self.son_goruntu is not None:
            noise = np.random.normal(0, self.noise_level * 255, self.son_goruntu.shape)
            self.son_goruntu = np.clip(self.son_goruntu + noise, 0, 255).astype(np.uint8)

    def _init_real_camera(self):
        """Ger√ßek kamerayƒ± ba≈ülat"""
        self.logger.info("üîß Fiziksel kamera ba≈ülatƒ±lƒ±yor...")
        try:
            from picamera2 import Picamera2

            self.camera = Picamera2()
            config = self.camera.create_preview_configuration(
                main={"format": "RGB888", "size": self.resolution}
            )
            self.camera.configure(config)
            self.camera.start()

            # Kamera kalibrasyonu y√ºkle (varsa)
            self._load_camera_calibration()

            self.logger.info("‚úÖ Fiziksel kamera hazƒ±r!")

        except Exception as e:
            self.logger.error(f"‚ùå Kamera ba≈ülatma hatasƒ±: {e}")
            self.simulation_mode = True
            self._init_simulation_camera()

    def _load_camera_calibration(self):
        """Kamera kalibrasyon parametrelerini y√ºkle"""
        try:
            # Kalibrasyon dosyasƒ± varsa y√ºkle
            # Bu ger√ßek uygulamada OpenCV kamera kalibrasyonu ile olu≈üturulur
            self.logger.info("üìê Kamera kalibrasyonu y√ºklendi")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Kalibrasyon y√ºklenemedi: {e}")

    async def goruntu_al(self) -> Optional[np.ndarray]:
        """
        üì∏ Kameradan g√∂r√ºnt√º al

        Returns:
            numpy.ndarray: BGR formatƒ±nda g√∂r√ºnt√º
        """
        try:
            if self.simulation_mode:
                return await self._simulation_goruntu_al()
            else:
                return await self._real_goruntu_al()
        except Exception as e:
            self.logger.error(f"‚ùå G√∂r√ºnt√º alma hatasƒ±: {e}")
            return None

    async def _simulation_goruntu_al(self) -> np.ndarray:
        """Sim√ºlasyon g√∂r√ºnt√ºs√º olu≈ütur"""
        # Dinamik sahte g√∂r√ºnt√º olu≈ütur
        goruntu = np.zeros(
            (self.resolution[1], self.resolution[0], 3), dtype=np.uint8)

        # Ye≈üil arkaplan (√ßimen)
        goruntu[:, :, 1] = 100  # Ye≈üil kanal

        # Zamanla deƒüi≈üen sahte engeller ekle
        t = time.time()

        # Sahte aƒüa√ß (kahverengi dikd√∂rtgen)
        if int(t) % 10 < 5:  # 5 saniye g√∂r√ºn√ºr, 5 saniye gizli
            cv2.rectangle(goruntu, (300, 200), (350, 400), (0, 50, 100), -1)

        # Sahte ta≈ü (gri daire)
        if int(t) % 15 < 7:
            cv2.circle(goruntu, (150, 350), 30, (100, 100, 100), -1)

        # Sahte ≈üarj istasyonu (parlak noktalar)
        if int(t) % 20 < 3:  # Arada ≈üarj istasyonu g√∂r√ºn
            cv2.circle(goruntu, (500, 300), 10, (255, 255, 255), -1)
            cv2.circle(goruntu, (520, 310), 8, (255, 255, 255), -1)

        # G√ºr√ºlt√º ekle
        noise = np.random.randint(0, 20, goruntu.shape, dtype=np.uint8)
        goruntu = cv2.add(goruntu, noise)

        self.son_goruntu = goruntu
        self.goruntu_sayaci += 1

        return goruntu

    async def _real_goruntu_al(self) -> np.ndarray:
        """Ger√ßek kameradan g√∂r√ºnt√º al"""
        if self.camera is None:
            return None

        # Picamera2'den g√∂r√ºnt√º al
        goruntu = self.camera.capture_array()

        # RGB'den BGR'ye √ßevir (OpenCV formatƒ±)
        goruntu = cv2.cvtColor(goruntu, cv2.COLOR_RGB2BGR)

        self.son_goruntu = goruntu
        self.goruntu_sayaci += 1

        return goruntu

    async def engel_analiz_et(self) -> Dict[str, Any]:
        """
        üöß G√∂r√ºnt√ºde engel analizi yap

        Returns:
            Dict: Tespit edilen engeller ve analiz sonu√ßlarƒ±
        """
        goruntu = await self.goruntu_al()
        if goruntu is None:
            return {"engeller": [], "analiz_basarili": False}

        try:
            # G√∂r√ºnt√ºy√º HSV'ye √ßevir
            hsv = cv2.cvtColor(goruntu, cv2.COLOR_BGR2HSV)

            # Engelleri tespit et
            engeller = []

            # Aƒüa√ß tespiti (kahverengi alanlar)
            agac_engelleri = await self._agac_tespit_et(hsv)
            engeller.extend(agac_engelleri)

            # Ta≈ü tespiti (gri alanlar)
            tas_engelleri = await self._tas_tespit_et(hsv)
            engeller.extend(tas_engelleri)

            # Genel engel tespiti (kontur analizi)
            genel_engeller = await self._genel_engel_tespit_et(goruntu)
            engeller.extend(genel_engeller)

            # Sonu√ßlarƒ± analiz et
            analiz_sonucu = {
                "engeller": [self._engel_to_dict(e) for e in engeller],
                "engel_sayisi": len(engeller),
                "en_yakin_engel": self._en_yakin_engel_bul(engeller),
                "guzergah_temiz": len(engeller) == 0,
                "analiz_basarili": True,
                "timestamp": datetime.now().isoformat()
            }

            self.logger.debug(
                f"üöß Engel analizi: {len(engeller)} engel tespit edildi")
            return analiz_sonucu

        except Exception as e:
            self.logger.error(f"‚ùå Engel analizi hatasƒ±: {e}")
            return {"engeller": [], "analiz_basarili": False}

    async def _agac_tespit_et(self, hsv: np.ndarray) -> List[Engel]:
        """Aƒüa√ß tespiti (kahverengi alanlar)"""
        kahverengi_mask = cv2.inRange(
            hsv,
            self.renk_araliklari["kahverengi"]["lower"],
            self.renk_araliklari["kahverengi"]["upper"]
        )

        # Morfolojik i≈ülemler
        kernel = np.ones((5, 5), np.uint8)
        kahverengi_mask = cv2.morphologyEx(
            kahverengi_mask, cv2.MORPH_CLOSE, kernel)
        kahverengi_mask = cv2.morphologyEx(
            kahverengi_mask, cv2.MORPH_OPEN, kernel)

        # Konturlarƒ± bul
        contours, _ = cv2.findContours(
            kahverengi_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        agaclar = []
        for contour in contours:
            alan = cv2.contourArea(contour)
            if self.engel_min_alan < alan < self.engel_max_alan:
                x, y, w, h = cv2.boundingRect(contour)

                # Aƒüa√ß tahmini mesafesi (basit hesaplama)
                mesafe = self._pixel_to_distance(w, h, "agac")

                agac = Engel(
                    tip=EngelTipi.AGAC,
                    konum=(x + w // 2, y + h // 2),
                    boyut=(w, h),
                    mesafe=mesafe,
                    guven_skoru=0.7
                )
                agaclar.append(agac)

        return agaclar

    async def _tas_tespit_et(self, hsv: np.ndarray) -> List[Engel]:
        """Ta≈ü tespiti (gri alanlar)"""
        gri_mask = cv2.inRange(
            hsv,
            self.renk_araliklari["gri"]["lower"],
            self.renk_araliklari["gri"]["upper"]
        )

        # Morfolojik i≈ülemler
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
        gri_mask = cv2.morphologyEx(gri_mask, cv2.MORPH_CLOSE, kernel)

        # Konturlarƒ± bul
        contours, _ = cv2.findContours(
            gri_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        taslar = []
        for contour in contours:
            alan = cv2.contourArea(contour)
            if self.engel_min_alan * 0.5 < alan < self.engel_max_alan * 0.3:  # Ta≈ülar daha k√º√ß√ºk
                x, y, w, h = cv2.boundingRect(contour)

                # Dairesellik kontrol√º (ta≈ülar genelde yuvarlak)
                perimeter = cv2.arcLength(contour, True)
                if perimeter > 0:
                    circularity = 4 * np.pi * alan / (perimeter * perimeter)
                    if circularity > 0.3:  # Yeterince yuvarlak
                        mesafe = self._pixel_to_distance(w, h, "tas")

                        tas = Engel(
                            tip=EngelTipi.TAS,
                            konum=(x + w // 2, y + h // 2),
                            boyut=(w, h),
                            mesafe=mesafe,
                            guven_skoru=circularity
                        )
                        taslar.append(tas)

        return taslar

    async def _genel_engel_tespit_et(self, goruntu: np.ndarray) -> List[Engel]:
        """Genel engel tespiti (kontur analizi)"""
        # Gri tonlamaya √ßevir
        gray = cv2.cvtColor(goruntu, cv2.COLOR_BGR2GRAY)

        # Gaussian blur uygula
        blurred = cv2.GaussianBlur(gray, (15, 15), 0)

        # Adaptive threshold
        thresh = cv2.adaptiveThreshold(
            blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2
        )

        # Konturlarƒ± bul
        contours, _ = cv2.findContours(
            thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        genel_engeller = []
        for contour in contours:
            alan = cv2.contourArea(contour)
            if self.engel_min_alan < alan < self.engel_max_alan:
                x, y, w, h = cv2.boundingRect(contour)

                # Aspect ratio kontrol√º
                aspect_ratio = w / h
                if 0.2 < aspect_ratio < 5.0:  # Makul aspect ratio
                    mesafe = self._pixel_to_distance(w, h, "bilinmeyen")

                    engel = Engel(
                        tip=EngelTipi.BILINMEYEN,
                        konum=(x + w // 2, y + h // 2),
                        boyut=(w, h),
                        mesafe=mesafe,
                        guven_skoru=0.5
                    )
                    genel_engeller.append(engel)

        return genel_engeller

    def _pixel_to_distance(self, width: int, height: int, engel_tipi: str) -> float:
        """
        Pixel boyutundan mesafe tahmini

        Bu basit bir hesaplama. Ger√ßek uygulamada kamera kalibrasyonu gerekli.
        """
        # Ger√ßek nesne boyutlarƒ± (metre)
        gercek_boyutlar = {
            "agac": 0.3,  # Aƒüa√ß g√∂vdesi yakla≈üƒ±k 30cm
            "tas": 0.15,  # Ta≈ü yakla≈üƒ±k 15cm
            "bilinmeyen": 0.2  # Ortalama 20cm
        }

        # Basit perspektif hesaplamasƒ±
        gercek_boyut = gercek_boyutlar.get(engel_tipi, 0.2)
        focal_length = 500  # Tahmini focal length (kalibrasyonla belirlenecek)

        # Mesafe = (Ger√ßek_Boyut * Focal_Length) / Pixel_Boyut
        pixel_boyut = max(width, height)
        if pixel_boyut > 0:
            mesafe = (gercek_boyut * focal_length) / pixel_boyut
            return max(0.1, min(10.0, mesafe))  # 0.1m - 10m arasƒ± sƒ±nƒ±rla

        return 2.0  # Varsayƒ±lan 2 metre

    def _en_yakin_engel_bul(self, engeller: List[Engel]) -> Optional[Dict[str, Any]]:
        """En yakƒ±n engeli bul"""
        if not engeller:
            return None

        en_yakin = min(engeller, key=lambda e: e.mesafe)
        return self._engel_to_dict(en_yakin)

    def _engel_to_dict(self, engel: Engel) -> Dict[str, Any]:
        """Engel objesini dictionary'ye √ßevir"""
        return {
            "tip": engel.tip.value,
            "konum": engel.konum,
            "boyut": engel.boyut,
            "mesafe": engel.mesafe,
            "guven_skoru": engel.guven_skoru
        }

    async def sarj_istasyonu_ara(self) -> Dict[str, Any]:
        """
        üîå ≈ûarj istasyonu arama (IR LED tespiti)

        ≈ûarj istasyonunda IR LED'ler olduƒüunu varsayar.
        """
        goruntu = await self.goruntu_al()
        if goruntu is None:
            return {"sarj_istasyonu_gorunur": False}

        try:
            # Gri tonlamaya √ßevir
            gray = cv2.cvtColor(goruntu, cv2.COLOR_BGR2GRAY)

            # Parlak noktalarƒ± bul (IR LED'ler)
            _, thresh = cv2.threshold(
                gray, self.sarj_ir_threshold, 255, cv2.THRESH_BINARY)

            # Konturlarƒ± bul
            contours, _ = cv2.findContours(
                thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            # IR LED'leri filtrele
            ir_noktalar = []
            for contour in contours:
                alan = cv2.contourArea(contour)
                if self.sarj_min_contour_area < alan < 1000:
                    x, y, w, h = cv2.boundingRect(contour)
                    merkez = (x + w // 2, y + h // 2)
                    ir_noktalar.append(merkez)

            # ≈ûarj istasyonu pattern'i ara (2 yakƒ±n LED)
            sarj_tespit = False
            sarj_merkezi = None
            sarj_mesafesi = 0.0
            sarj_yonu = 0.0

            if len(ir_noktalar) >= 2:
                # En yakƒ±n 2 LED'i bul
                for i in range(len(ir_noktalar)):
                    for j in range(i + 1, len(ir_noktalar)):
                        p1, p2 = ir_noktalar[i], ir_noktalar[j]
                        mesafe = np.sqrt((p1[0] - p2[0]) **
                                         2 + (p1[1] - p2[1])**2)

                        # LED'ler arasƒ± mesafe uygun mu? (20-100 pixel)
                        if 20 < mesafe < 100:
                            sarj_tespit = True
                            sarj_merkezi = (
                                (p1[0] + p2[0]) // 2, (p1[1] + p2[1]) // 2)

                            # Mesafe tahmini (merkez pixel'den)
                            img_center_x = self.resolution[0] // 2
                            pixel_distance = abs(
                                sarj_merkezi[0] - img_center_x)
                            sarj_mesafesi = self._pixel_to_distance(
                                int(mesafe), int(mesafe), "sarj")

                            # Y√∂n hesaplama (radyan)
                            sarj_yonu = np.arctan2(sarj_merkezi[1] - self.resolution[1] // 2,
                                                   sarj_merkezi[0] - img_center_x)
                            break

                    if sarj_tespit:
                        break

            sonuc = {
                "sarj_istasyonu_gorunur": sarj_tespit,
                "konum": sarj_merkezi,
                "mesafe": sarj_mesafesi,
                "yon": sarj_yonu,
                "guven_skoru": 0.8 if sarj_tespit else 0.0,
                "ir_nokta_sayisi": len(ir_noktalar)
            }

            if sarj_tespit:
                self.logger.info(
                    f"üîå ≈ûarj istasyonu tespit edildi! Mesafe: {sarj_mesafesi:.2f}m")

            return sonuc

        except Exception as e:
            self.logger.error(f"‚ùå ≈ûarj istasyonu arama hatasƒ±: {e}")
            return {"sarj_istasyonu_gorunur": False}

    async def otlak_analiz_et(self) -> Dict[str, Any]:
        """
        üå± Otlak alanƒ± analizi (bi√ßilecek alan tespiti)

        Ye≈üil alanlarƒ± tespit eder ve bi√ßme √∂nceliƒüi belirler.
        """
        goruntu = await self.goruntu_al()
        if goruntu is None:
            return {"analiz_basarili": False}

        try:
            # HSV'ye √ßevir
            hsv = cv2.cvtColor(goruntu, cv2.COLOR_BGR2HSV)

            # Ye≈üil alan maskesi
            yesil_mask = cv2.inRange(
                hsv,
                self.renk_araliklari["yesil"]["lower"],
                self.renk_araliklari["yesil"]["upper"]
            )

            # Morfolojik i≈ülemler
            kernel = np.ones((5, 5), np.uint8)
            yesil_mask = cv2.morphologyEx(yesil_mask, cv2.MORPH_OPEN, kernel)
            yesil_mask = cv2.morphologyEx(yesil_mask, cv2.MORPH_CLOSE, kernel)

            # Ye≈üil alan istatistikleri
            total_pixels = yesil_mask.shape[0] * yesil_mask.shape[1]
            yesil_pixels = cv2.countNonZero(yesil_mask)
            yesil_orani = yesil_pixels / total_pixels

            # Otlak yoƒüunluƒüu analizi (ye≈üil tonlama √ße≈üitliliƒüi)
            yesil_alan = cv2.bitwise_and(hsv, hsv, mask=yesil_mask)
            if yesil_pixels > 0:
                # V kanalƒ± (brightness) istatistikleri
                v_channel = yesil_alan[:, :, 2]
                v_nonzero = v_channel[v_channel > 0]

                if len(v_nonzero) > 0:
                    ot_yogunlugu = np.mean(v_nonzero) / 255.0
                    ot_uniformlugu = 1.0 - (np.std(v_nonzero) / 255.0)
                else:
                    ot_yogunlugu = 0.0
                    ot_uniformlugu = 0.0
            else:
                ot_yogunlugu = 0.0
                ot_uniformlugu = 0.0

            # Bi√ßme √∂nceliƒüi hesapla
            bicme_onceligi = yesil_orani * ot_yogunlugu

            analiz_sonucu = {
                "analiz_basarili": True,
                "yesil_alan_orani": yesil_orani,
                "ot_yogunlugu": ot_yogunlugu,
                "ot_uniformlugu": ot_uniformlugu,
                "bicme_onceligi": bicme_onceligi,
                "bicme_onerisi": bicme_onceligi > 0.3,
                "timestamp": datetime.now().isoformat()
            }

            self.logger.debug(
                f"üå± Otlak analizi: %{yesil_orani*100:.1f} ye≈üil alan")
            return analiz_sonucu

        except Exception as e:
            self.logger.error(f"‚ùå Otlak analizi hatasƒ±: {e}")
            return {"analiz_basarili": False}

    def goruntu_kaydet(self, dosya_adi: str):
        """Mevcut g√∂r√ºnt√ºy√º kaydet"""
        if self.son_goruntu is not None:
            try:
                cv2.imwrite(
                    f"logs/{dosya_adi}_{self.goruntu_sayaci}.jpg", self.son_goruntu)
                self.logger.info(
                    f"üíæ G√∂r√ºnt√º kaydedildi: {dosya_adi}_{self.goruntu_sayaci}.jpg")
            except Exception as e:
                self.logger.error(f"‚ùå G√∂r√ºnt√º kaydetme hatasƒ±: {e}")

    def get_kamera_durumu(self) -> Dict[str, Any]:
        """Kamera durumu bilgisi"""
        return {
            "aktif": self.camera is not None or self.simulation_mode,
            "sim√ºlasyon": self.simulation_mode,
            "resolution": self.resolution,
            "framerate": self.framerate,
            "goruntu_sayaci": self.goruntu_sayaci,
            "son_goruntu_zamani": datetime.now().isoformat() if self.son_goruntu is not None else None
        }

    def __del__(self):
        """Kamera i≈ülemci kapatƒ±lƒ±yor"""
        if hasattr(self, 'logger'):
            self.logger.info("üëã Kamera i≈ülemci kapatƒ±lƒ±yor...")

        if hasattr(self, 'camera') and self.camera is not None:
            try:
                self.camera.stop()
                self.camera.close()
            except:
                pass
                pass
